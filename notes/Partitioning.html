<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><title>Partitioning</title><link rel="icon" href="/favicon.ico"/><meta name="next-head-count" content="4"/><link rel="preload" href="https://abtv.github.io/_next/static/css/3fecac13a3874b4c2251.css" as="style"/><link rel="stylesheet" href="https://abtv.github.io/_next/static/css/3fecac13a3874b4c2251.css" data-n-g=""/><link rel="preload" href="https://abtv.github.io/_next/static/css/065d9f208d7ce6a4c5de.css" as="style"/><link rel="stylesheet" href="https://abtv.github.io/_next/static/css/065d9f208d7ce6a4c5de.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="https://abtv.github.io/_next/static/chunks/polyfills-a40ef1678bae11e696dba45124eadd70.js"></script><script src="https://abtv.github.io/_next/static/chunks/webpack-ea2473d7256b97f36886.js" defer=""></script><script src="https://abtv.github.io/_next/static/chunks/framework-0441fae7fd130f37dee1.js" defer=""></script><script src="https://abtv.github.io/_next/static/chunks/main-d1e3ce7bd5cd46c1581b.js" defer=""></script><script src="https://abtv.github.io/_next/static/chunks/pages/_app-68998cd3c2087b94033f.js" defer=""></script><script src="https://abtv.github.io/_next/static/chunks/832-1d93ef3dd096bfa087f2.js" defer=""></script><script src="https://abtv.github.io/_next/static/chunks/pages/notes/%5Bid%5D-63cdc919fe449cbe88aa.js" defer=""></script><script src="https://abtv.github.io/_next/static/bcp17DAePISG4rlZsEEZz/_buildManifest.js" defer=""></script><script src="https://abtv.github.io/_next/static/bcp17DAePISG4rlZsEEZz/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="page-wrapper"><div class="page-content"><div class="Post_article__f3v0Q"><div class="Post_header__2s4s1"><a href="/">← Main page</a></div><div class="Post_header__2s4s1"><h2>Partitioning</h2></div><main class="Post_main__2fGnD"><div class="Post_grid__1uhVO"><div class="note-wrapper"><h3>Partitioning</h3>
<p>Partitioning is a process of storing one dataset in several partitions in one dataset. Usually each node stores one or some  small subset of partitions. This allows to svale whenthe whole dataset is too big to be handled by a single node.</p>
<p>Usually partitioning is used in combination with replication.</p>
<h3>Partitioning by key range</h3>
<p>Data can be partitioned by key range. This approach is simple and allows to make range requests fast.</p>
<p>On the other hand, this approach is prone to create hot spots. Hot spot is a node which has too much data comparing to other nodes.</p>
<h3>Partitioning by hash key</h3>
<p>Data can be partitioned not by key itself but its hash. This approach creates more uniformed distribution of data.</p>
<p>On the other hand, range queries will require to hit all partitions and it will be slower. It will be as slow as the slowest partition response.</p>
<h3>Partitioning and secondary indexes</h3>
<ol>
<li>If secondary infeces are supported it will require to hit all partitions to run a query.</li>
<li>We can also partition secondary index itself by term: some range of terms will be stored in one partition, some in another, etc. This approach has the same downside as with followers: writes to some nodes may be slower than to other nodes and we will not be able to read the written fata immediately.</li>
</ol>
<h3>Rebalancing partitions</h3>
<p>We may want to add more partitions if:</p>
<ol>
<li>We need better throughtput with the same amount of data.</li>
<li>We significanttly increase our dataset and want to keep throughtput at the same level.</li>
<li>We need to replace a failed node.</li>
</ol>
<p>&quot;Key mod N&quot; approach doesn&#x27;t work because if we increase number of machines (N) it will cause significant data move.</p>
<p>We can create a fixed number of partitions from the beginning, like 1000 partitions in 10 nodes (each node has 100 partitions). Later if we add more nodes we just need to move some of existing partitions from each node and we will not touch other partitions. Elasticsearch uses this approach.</p>
<p>Wr can also create dynamuc partitions: if our partition exceeds dome limit we will break it into two partitions. We can also merge small partitions after mass deletion of records. Mongodb uses dynamic partitioning.</p>
<p>Cassandra uses fixed number of partitions per node. When a new node is added part of existing partitions split into two and then moved to the new node.</p>
<h3>Request routing</h3>
<p>Client can connect to:</p>
<ol>
<li>Partition node and the node will either return data or request an appropriate node and then return the data to client.</li>
<li>Proxy which is aware about partitions and will request data from an appropriate node.</li>
<li>Partition directly. In this case client should be aware about nodes and partitions.</li>
</ol>
<h3>Related notes</h3>
<ul>
<li><a href="/notes/Engineering">Engineering →</a></li>
</ul></div></div></main></div></div><footer class="page-footer"><a href="/">Andrey Butov 2014-2021</a></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"title":"Partitioning","content":"### Partitioning\nPartitioning is a process of storing one dataset in several partitions in one dataset. Usually each node stores one or some  small subset of partitions. This allows to svale whenthe whole dataset is too big to be handled by a single node.\n\nUsually partitioning is used in combination with replication.\n\n### Partitioning by key range\nData can be partitioned by key range. This approach is simple and allows to make range requests fast.\n\nOn the other hand, this approach is prone to create hot spots. Hot spot is a node which has too much data comparing to other nodes.\n\n### Partitioning by hash key\nData can be partitioned not by key itself but its hash. This approach creates more uniformed distribution of data.\n\nOn the other hand, range queries will require to hit all partitions and it will be slower. It will be as slow as the slowest partition response.\n\n### Partitioning and secondary indexes\n1. If secondary infeces are supported it will require to hit all partitions to run a query.\n2. We can also partition secondary index itself by term: some range of terms will be stored in one partition, some in another, etc. This approach has the same downside as with followers: writes to some nodes may be slower than to other nodes and we will not be able to read the written fata immediately.\n\n### Rebalancing partitions\nWe may want to add more partitions if:\n1. We need better throughtput with the same amount of data.\n2. We significanttly increase our dataset and want to keep throughtput at the same level.\n3. We need to replace a failed node.\n\n\"Key mod N\" approach doesn't work because if we increase number of machines (N) it will cause significant data move.\n\nWe can create a fixed number of partitions from the beginning, like 1000 partitions in 10 nodes (each node has 100 partitions). Later if we add more nodes we just need to move some of existing partitions from each node and we will not touch other partitions. Elasticsearch uses this approach.\n\nWr can also create dynamuc partitions: if our partition exceeds dome limit we will break it into two partitions. We can also merge small partitions after mass deletion of records. Mongodb uses dynamic partitioning.\n\nCassandra uses fixed number of partitions per node. When a new node is added part of existing partitions split into two and then moved to the new node.\n\n### Request routing\nClient can connect to:\n1. Partition node and the node will either return data or request an appropriate node and then return the data to client.\n2. Proxy which is aware about partitions and will request data from an appropriate node.\n3. Partition directly. In this case client should be aware about nodes and partitions.\n\n### Related notes\n- [Engineering \u0026rarr;](/notes/Engineering)"},"__N_SSG":true},"page":"/notes/[id]","query":{"id":"Partitioning"},"buildId":"bcp17DAePISG4rlZsEEZz","assetPrefix":"https://abtv.github.io","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>